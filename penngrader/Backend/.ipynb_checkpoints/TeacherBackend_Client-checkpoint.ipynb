{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes: parameters to create homeowkr\n",
    "#\n",
    "# COURSE\n",
    "# SEMESTER\n",
    "# YEAR\n",
    "# HOMEWORK_NUMBER\n",
    "# MAX_SCORE\n",
    "# DEADLINE (maybe just put this in 'view scores' section)\n",
    "# \n",
    "\n",
    "import json\n",
    "import urllib.request\n",
    "import dill\n",
    "import base64\n",
    "import types\n",
    "from urllib.error import HTTPError\n",
    "import ast\n",
    "import types\n",
    "\n",
    "api_url = 'https://qk1b0ut5z2.execute-api.us-east-1.amazonaws.com/default/TeacherBackend'\n",
    "api_key = 'LOEn9CIMqFGWBc9UCEyk53SxS0le2Vr2165AkDk4'\n",
    "\n",
    "def get_imported_libraries():\n",
    "    '''Retruns a list of (package name, package shortname, fromlist item) tuples for all imported packages'''\n",
    "    imported_packages = set()\n",
    "    for name, val in list(globals().items()):\n",
    "        if type(val) == types.ModuleType and name not in ['__builtin__','__builtins__']:\n",
    "            imported_packages.add((val.__name__, name, None))\n",
    "        elif type(val) == types.FunctionType and val.__module__ not in ['__main__']:\n",
    "            imported_packages.add((val.__module__, val.__module__, val.__name__))\n",
    "    return list(imported_packages)  \n",
    "\n",
    "def serialize(obj):\n",
    "    '''Dill serializes Python object into a UTF-8 string'''\n",
    "    byte_serialized = dill.dumps(obj, recurse = True)\n",
    "    return base64.b64encode(byte_serialized).decode(\"utf-8\")\n",
    "\n",
    "def validate_test_cases(test_cases):\n",
    "    for test_id in test_cases:\n",
    "        if not type(test_cases[test_id]) == types.FunctionType:\n",
    "            print('Error: The test_case dictionary defined above should map a string (i.e test case name) to a function.')\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "class PennGraderBackend:\n",
    "    \n",
    "    def __init__(self, homework_id, secret_key):\n",
    "        self.homework_id = homework_id\n",
    "        self.secret_key = secret_key\n",
    "        self.validate_credentials()\n",
    "            \n",
    "    def validate_credentials(self):\n",
    "        payload = { \n",
    "            'homework_id' : self.homework_id, \n",
    "            'secret_key' : self.secret_key, \n",
    "            'request_type': 'credentials', \n",
    "            'payload' : serialize(None)\n",
    "        }\n",
    "        return self.send_payload(payload, api_url, api_key)\n",
    "    \n",
    "    def upload_test_cases(self, test_cases):\n",
    "        payload = { \n",
    "            'homework_id' : self.homework_id, \n",
    "            'secret_key' : self.secret_key, \n",
    "            'request_type' : 'tests',\n",
    "            'payload' : serialize({\n",
    "                'libraries'  : get_imported_libraries(),\n",
    "                'test_cases' : test_cases\n",
    "            })\n",
    "        }\n",
    "        if validate_test_cases(test_cases):\n",
    "            self.send_payload(payload, api_url, api_key)\n",
    "        \n",
    "    def send_payload(self, payload, api_endpoint, api_key):\n",
    "        params = json.dumps(payload).encode('utf-8')\n",
    "        headers = {'content-type': 'application/json', 'x-api-key': api_key}\n",
    "        request = urllib.request.Request(api_endpoint, data = params, headers = headers)\n",
    "        try:\n",
    "            response = urllib.request.urlopen(request)\n",
    "            print('{}'.format(response.read().decode('utf-8')))\n",
    "            return True\n",
    "        except HTTPError as error:\n",
    "            print('Error: {}'.format(error.read().decode(\"utf-8\")))\n",
    "            return False  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PennGrader: Teacher Backend\n",
    "\n",
    "This notebook will let you quickly create homeworks and analyze student's submissions.\n",
    "\n",
    "### Step 1: Configuration \n",
    "Fill in the cell below with the HOMEWORK_ID and SECRET_KEY obtained when you first created your homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOMEWORK_ID = 'test_homework_id' \n",
    "SECRET_KEY = 'test_secret_key'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: {\"message\": \"Internal server error\"}\n"
     ]
    }
   ],
   "source": [
    "backend = PennGraderBackend(homework_id = HOMEWORK_ID, secret_key = SECRET_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Import Libraries\n",
    "In the cell below import all libraries needed for grading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn \n",
    "from sklearn.metrics import accuracy_score, auc\n",
    "# from sklearn import svm\n",
    "import pandas as pd\n",
    "# #import tensorflow\n",
    "# import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score([1,2],[3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc([1,2],[3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpy', 'np', None),\n",
       " ('dill', 'dill', None),\n",
       " ('ast', 'ast', None),\n",
       " ('sklearn', 'sklearn', None),\n",
       " ('sklearn.metrics.classification',\n",
       "  'sklearn.metrics.classification',\n",
       "  'accuracy_score'),\n",
       " ('urllib', 'urllib', None),\n",
       " ('pandas', 'pd', None),\n",
       " ('sklearn.metrics.ranking', 'sklearn.metrics.ranking', 'auc'),\n",
       " ('json', 'json', None),\n",
       " ('base64', 'base64', None),\n",
       " ('types', 'types', None)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_imported_libraries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Write Test Cases\n",
    "Define a test case function for each question.\n",
    "\n",
    "A test case function takes in a single input containing the student's answer and returns a tuple `(student score:int, maximum score:int)`. See example below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_case_0_1(answer): # [answer] can be of any type (i.e a function, a string, a dataframe, a class, etc) #\n",
    "    student_score = 0\n",
    "    max_score     = 2\n",
    "\n",
    "    if answer == 'Correct answer':\n",
    "        student_score = 2\n",
    "    elif answer == 'Not so correct answer':\n",
    "        student_score = 1\n",
    "    else:\n",
    "        student_score = 0\n",
    "        \n",
    "    return (student_score, max_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below fill in the `test_cases` dictionary to map the test case's name (homework section for example) to the cooresponding function you defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = {\n",
    "        '0.1' : test_case_0_1 # Test cases for section 0.1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gAN9cQBYAwAAADAuMXEBY2RpbGwuX2RpbGwKX2NyZWF0ZV9mdW5jdGlvbgpxAihjZGlsbC5fZGlsbApfbG9hZF90eXBlCnEDWAgAAABDb2RlVHlwZXEEhXEFUnEGKEsBSwBLA0sCS0NDMGQBfQFkAn0CfABkA2sCchZkAn0BbhJ8AGQEawJyJGQFfQFuBGQBfQF8AXwCZgJTAHEHKE5LAEsCWA4AAABDb3JyZWN0IGFuc3dlcnEIWBUAAABOb3Qgc28gY29ycmVjdCBhbnN3ZXJxCUsBdHEKKVgGAAAAYW5zd2VycQtYDQAAAHN0dWRlbnRfc2NvcmVxDFgJAAAAbWF4X3Njb3JlcQ2HcQ5YHgAAADxpcHl0aG9uLWlucHV0LTgtZTBjMTkzYmVkYjA5PnEPWA0AAAB0ZXN0X2Nhc2VfMF8xcRBLAUMQAAEEAQQCCAEGAQgBBgIEAnERKSl0cRJScRN9cRRoEE5OfXEVTnRxFlJxF3Mu'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serialize(test_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4:  Upload Test Cases\n",
    "Run the cell below to upload/update the homework's test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Test cases updated successfully.\n"
     ]
    }
   ],
   "source": [
    "backend.upload_test_cases(test_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    "\n",
    " ### Step 5:  View Grades\n",
    "\n",
    "\n",
    " \n",
    " \n",
    " \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
